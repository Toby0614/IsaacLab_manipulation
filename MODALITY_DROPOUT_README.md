# Modality Dropout System - Quick Start

Implements vision failure simulation for robustness studies as described in `poe2.pdf`.

## ðŸš€ Quickest Start (1 line!)

```bash
# Train with vision dropout - wraps your existing system automatically
python scripts/rsl_rl/train_with_dropout.py --task=Isaac-Franka-PickPlace-Direct-v0 --dropout_mode=hard
```

That's it! Your existing environment will now experience intermittent vision failures during training.

## ðŸ“‹ What It Does

- **Hard dropout**: Random complete vision blackouts (0.5-3 seconds)
- **Soft dropout**: Noisy/corrupted vision (Gaussian noise, cutouts, speckles)
- **Phase-aware**: Different dropout rates during reach/grasp/lift/transport/place
- **Duration-based**: Continuous failures over multiple timesteps
- **Non-invasive**: Works with your existing configs without modification

## ðŸŽ¯ Usage Modes

### Training

```bash
# M1: No dropout (baseline)
python scripts/rsl_rl/train.py --task=Isaac-Franka-PickPlace-Direct-v0

# M3: Train WITH dropout (robust baseline)
python scripts/rsl_rl/train_with_dropout.py --task=Isaac-Franka-PickPlace-Direct-v0 --dropout_mode=hard

# Phase-aware dropout
python scripts/rsl_rl/train_with_dropout.py --task=Isaac-Franka-PickPlace-Direct-v0 --dropout_mode=phase

# Soft dropout (noise instead of blackout)
python scripts/rsl_rl/train_with_dropout.py --task=Isaac-Franka-PickPlace-Direct-v0 --dropout_mode=soft
```

### Custom Parameters

```bash
# Adjust dropout frequency and duration
python scripts/rsl_rl/train_with_dropout.py \
    --task=Isaac-Franka-PickPlace-Direct-v0 \
    --dropout_mode=hard \
    --dropout_prob=0.03 \
    --dropout_duration_min=10 \
    --dropout_duration_max=60 \
    --enable_phase_detection
```

### Evaluation

```python
# In your play/eval script
from source.Manipulation_policy.Manipulation_policy.tasks.manager_based.manipulation.stack.mdp.dropout_env_wrapper import VecEnvDropoutWrapper
from source.Manipulation_policy.Manipulation_policy.tasks.manager_based.manipulation.stack.mdp.modality_dropout_cfg import EvalDropoutCfg

# Create base env
env = gym.make("Isaac-Franka-PickPlace-Direct-v0", num_envs=256)

# Wrap with deterministic dropout for testing
eval_cfg = EvalDropoutCfg()
eval_cfg.eval_dropout_start_step = 30  # Dropout at 1.5 seconds
eval_cfg.eval_dropout_duration = 20    # Lasts 1.0 second
env = VecEnvDropoutWrapper(env, eval_cfg)

# Test policy
success_rate = evaluate(policy, env)
```

## ðŸ“Š Experiment Design (from poe2.pdf)

To reproduce paper results, train 4 models:

| Model | Vision Obs | Force Obs | Dropout Training | Purpose |
|-------|-----------|-----------|------------------|---------|
| **M1** | RGB-D | âŒ | âŒ | Baseline |
| **M2** | RGB-D | âœ… | âŒ | Force helps? |
| **M3** | RGB-D | âŒ | âœ… | Robust training helps? |
| **M4** | RGB-D | âœ… | âœ… | Best (force + robust) |

Then evaluate all 4 models under various dropout conditions:
- No dropout (clean vision)
- Short dropout (0.5s)
- Medium dropout (1.5s)  
- Long dropout (3.0s)
- Phase-specific dropout (during grasp, lift, transport, etc.)

## ðŸ—‚ï¸ Files Created

```
source/Manipulation_policy/Manipulation_policy/tasks/manager_based/manipulation/stack/mdp/
â”œâ”€â”€ modality_dropout_cfg.py              # Configuration classes (presets + custom)
â”œâ”€â”€ modality_dropout_manager.py          # Core dropout logic
â”œâ”€â”€ modality_dropout_observations.py     # Dropout-aware observation wrappers
â”œâ”€â”€ dropout_env_wrapper.py               # Environment wrapper (RECOMMENDED)
â”œâ”€â”€ phase_detector.py                    # Automatic phase detection
â””â”€â”€ MODALITY_DROPOUT_GUIDE.md           # Detailed documentation

scripts/rsl_rl/
â””â”€â”€ train_with_dropout.py                # Modified training script with dropout

MODALITY_DROPOUT_README.md              # This file
```

## âš™ï¸ How It Works

1. **ModalityDropoutManager**: Tracks per-environment dropout state
   - Randomly starts dropout events based on probability
   - Maintains continuous dropout for specified duration
   - Handles hard/soft/mixed corruption modes

2. **Dropout-Aware Observations**: Modified observation functions that:
   - Call original observation functions (your existing code)
   - Apply dropout via manager if present
   - Return corrupted observations transparently

3. **Environment Wrapper**: Handles lifecycle
   - Creates and attaches dropout manager to env
   - Updates dropout state each step
   - Resets dropout on episode boundaries
   - Optional: Detects task phases automatically

## ðŸ”§ Advanced Usage

### Programmatic Integration

If you prefer code over CLI:

```python
import gymnasium as gym
from source.Manipulation_policy.Manipulation_policy.tasks.manager_based.manipulation.stack.mdp.dropout_env_wrapper import VecEnvDropoutWrapper
from source.Manipulation_policy.Manipulation_policy.tasks.manager_based.manipulation.stack.mdp.modality_dropout_cfg import HardDropoutTrainingCfg

# Create env
env = gym.make("Isaac-Franka-PickPlace-Direct-v0", num_envs=4096)

# Configure dropout
dropout_cfg = HardDropoutTrainingCfg()
dropout_cfg.dropout_probability = 0.025  # Adjust as needed
dropout_cfg.dropout_duration_range = (15, 60)

# Wrap
env = VecEnvDropoutWrapper(env, dropout_cfg)

# Train normally
agent.learn(env)
```

### Custom Dropout Configuration

```python
from source.Manipulation_policy.Manipulation_policy.tasks.manager_based.manipulation.stack.mdp.modality_dropout_cfg import ModalityDropoutCfg

cfg = ModalityDropoutCfg(
    enabled=True,
    dropout_mode="hard",              # "hard", "soft", or "mixed"
    dropout_probability=0.02,          # 2% chance per step
    dropout_duration_range=(10, 50),   # 0.5-2.5 seconds
    dropout_rgb=True,                  # Apply to RGB
    dropout_depth=True,                # Apply to depth
    phase_aware=False,                 # Uniform across phases
)
```

### Phase-Aware Dropout

```python
from source.Manipulation_policy.Manipulation_policy.tasks.manager_based.manipulation.stack.mdp.modality_dropout_cfg import PhaseBasedDropoutCfg

cfg = PhaseBasedDropoutCfg()
cfg.phase_dropout_config = {
    "reach": 0.01,      # 1% during reach
    "grasp": 0.05,      # 5% during grasp (critical!)
    "lift": 0.03,       # 3% during lift
    "transport": 0.06,  # 6% during transport (highest)
    "place": 0.04,      # 4% during place
}

env = VecEnvDropoutWrapper(env, cfg, enable_phase_detection=True)
```

## ðŸ“ˆ Logging & Monitoring

```python
# Get dropout statistics
stats = env.get_dropout_stats()
print(stats)
# {
#     'dropout_active_count': 123,
#     'dropout_active_fraction': 0.03,
#     'avg_remaining_steps': 15.2
# }

# Log to your training logger
logger.log_scalar("dropout/active_fraction", stats['dropout_active_fraction'])
```

## â“ FAQ

**Q: Will this slow down training?**
A: Negligible impact (~1-2%). Dropout is applied on GPU tensors, very fast.

**Q: Does it work with my existing configs?**
A: Yes! The wrapper approach requires zero config changes. Just wrap the env.

**Q: Can I disable dropout for some cameras?**
A: Yes, set `dropout_cfg.dropout_rgb = False` or `dropout_cfg.dropout_depth = False`.

**Q: How do I know if dropout is working?**
A: Check logs for `[INFO] Modality dropout ENABLED`, or call `env.get_dropout_stats()`.

**Q: Can I use this for evaluation only?**
A: Yes, use `EvalDropoutCfg()` which provides deterministic dropout schedules.

## ðŸ“š Full Documentation

See [`MODALITY_DROPOUT_GUIDE.md`](source/Manipulation_policy/Manipulation_policy/tasks/manager_based/manipulation/stack/MODALITY_DROPOUT_GUIDE.md) for:
- Detailed API documentation
- All configuration options
- Phase detection setup
- Evaluation protocols
- Troubleshooting guide

## ðŸ™ Citation

Based on recommendations from `poe2.pdf` for robust vision-based manipulation research.

```bibtex
@misc{isaaclab,
  author = {Isaac Lab Project Contributors},
  title = {Isaac Lab},
  year = {2025},
  url = {https://github.com/isaac-sim/IsaacLab}
}
```

## ðŸ› Issues

If you encounter any problems:
1. Check that your observation config uses `mdp.multi_cam_tensor_chw_with_dropout` (if not using wrapper)
2. Verify `env.dropout_manager` exists on the unwrapped env
3. Set `dropout_cfg.enabled = True`
4. See full troubleshooting guide in MODALITY_DROPOUT_GUIDE.md

## âœ… Verification

Test that dropout is working:

```python
import gymnasium as gym
from source.Manipulation_policy.Manipulation_policy.tasks.manager_based.manipulation.stack.mdp.dropout_env_wrapper import VecEnvDropoutWrapper
from source.Manipulation_policy.Manipulation_policy.tasks.manager_based.manipulation.stack.mdp.modality_dropout_cfg import HardDropoutTrainingCfg

# Create and wrap env
env = gym.make("Isaac-Franka-PickPlace-Direct-v0", num_envs=16)
env = VecEnvDropoutWrapper(env, HardDropoutTrainingCfg())

# Step and check
obs = env.reset()
for i in range(100):
    obs, reward, done, info = env.step(env.action_space.sample())
    stats = env.get_dropout_stats()
    if stats['dropout_active_count'] > 0:
        print(f"âœ“ Dropout active in {stats['dropout_active_count']} envs at step {i}")
        break
else:
    print("âœ— No dropout observed in 100 steps (might be rare, run longer)")
```

---

**Ready to train robust policies? Start with:**
```bash
python scripts/rsl_rl/train_with_dropout.py --task=Isaac-Franka-PickPlace-Direct-v0 --dropout_mode=hard
```

